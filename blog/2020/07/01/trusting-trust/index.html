<html>
<head>
    <title>A Discussion of Ken Thompson's "Reflections on Trusting Trust"</title>
    <meta charset='UTF-8'>
    <meta content='width=device-width, initial-scale=1' name='viewport'/>

    <meta name='description' content='Manan Shah is a senior at Stanford University.'>
    <meta name='keywords' content='machine-intelligence'>
    <meta name='author' content='Manan Shah'>

    <link href='/css/callout.css' rel='stylesheet'/>
    <link href='/css/blog.css' rel='stylesheet'/>
    <link href='/css/trac.css' rel='stylesheet'/>
    <link href='/css/markdown.css' rel='stylesheet'/>

    <script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  jax: ['input/TeX', 'output/HTML-CSS'],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    extensions: ['color.js']
  },
  messageStyle: 'none',
  'HTML-CSS': { preferredFont: 'TeX', availableFonts: ['STIX','TeX'] }
});
</script>

<script src='//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML' type='text/javascript'></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

    <script src="/assets/katex.min.js"></script>
    <script src="/assets/pseudocode.min.js" type="text/javascript"></script>
    <link rel="stylesheet" href="/assets/pseudocode.min.css" type="text/css">

</head>
<body>
<div class='content'>
    <div class='nav'>
    <ul class='wrap'>
        <li><a href='/'>Home</a></li>
        <li><a href='/blog'>Blog</a></li>
        <li><a href='/feed.xml'>RSS</a></li>
    </ul>
</div>
    <div class='front-matter'>
        <div class='wrap'>
            <h1>A Discussion of Ken Thompson's "Reflections on Trusting Trust"</h1>
            <h4>Ken Thompson's Turing award lecture "Reflections on Trusting Trust" took me a while to grasp, but proved immensely rewarding to understand. Here, I discuss the exploit presented in an approachable manner.</h4>
            <div class='bylines'>
                <div class='byline'>
                    <h3>Published&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Categories</h3>
                    <p>01 July 2020&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;machine-intelligence</p>
                </div>
            </div>
            <div class='clear'></div>
        </div>
    </div>
    <div class='wrap article'>
        <p>Thompson’s “Reflections on Trusting Trust” <a class="citation" href="#thompson1984reflections">(Thompson, 1984)</a> is
a short and effective paper discussing a fascinating exploit and its
implications on trust in computer security. The following discussion is based on
the aforementioned paper as well as discussions
<a href="https://scienceblogs.com/goodmath/2007/04/15/strange-loops-dennis-ritchie-a">here</a>,
<a href="https://softwareengineering.stackexchange.com/questions/184874/is-ken-thompsons-compiler-hack-still-a-threat?noredirect=1&amp;lq=1">here</a>,
and
<a href="https://stackoverflow.com/questions/38005656/how-can-a-compiler-compile-itself/38005659#38005659">here</a>.</p>

<h3 id="introduction">Introduction</h3>

<p>To begin, consider the C compiler, which is bootstrapped and written in C. 
For simplicity, let the compiler routine be represented as follows.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>compile (code)
{
  /* Do regular compilation things */
  ...
}
</code></pre></div></div>

<p>The Unix kernel has a <code class="highlighter-rouge">login</code> command that accepts an encrypted password and
compares it to the stored user password in <code class="highlighter-rouge">/etc/password</code>, allowing access on a
match and rejecting access otherwise. Say we wanted to insert a backdoor into
this command, which would accept either the encrypted password or a particular
known password. Doing so would allow a third-party user to gain access to any
system given knowledge of this additional acceptable password.</p>

<h3 id="a-trivial-backdoor">A Trivial Backdoor</h3>

<p>As a first attempt to insert such a backdoor, we can modify the C compiler to
compile the backdoor instead of the traditional login code, but behave normally
in all other situations. In particular, our modification might look like</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>compile (code)
{
  /* If the code we're compiling is code for the Unix login command */
  if (match (code, login_code_pattern))
  {
    compile (backdoor);
    return;
  }

  else
  {
    /* Do regular compilation things */
    ...
  }
}
</code></pre></div></div>

<p>This would work perfectly, so that whenever the Unix kernel was compiled,
the code generated by the compiler would include our desired backdoor. However,
our exploit isn’t fooling anyone: a simple look at the C compiler source code
would immediately raise complaints.</p>

<h3 id="thompsons-solution">Thompson’s Solution</h3>

<p>The brilliance of Thompson’s exploit is the ability to insert such a backdoor in
the C compiler, so that the compiler inserts the backdoor <em>when it compiles
itself</em> and leaves no trace that the exploit was performed (aside from within
the compiled assembly code).</p>

<p>We begin by further modifying the C compiler with a malicious program that is
executed when the compiler compiles itself. In particular, when the compiler is
asked to compile itself, it instead compiles a version of itself with the login
backdoor and the malicious program inserted. To summarize, our compiler now
includes two new procedures: <sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup></p>
<ol>
  <li>If asked to compile the Unix kernel login code, it instead compiles the
backdoor code</li>
  <li>If asked to compile itself, it instead compiles a version of itself with both
the logic in (1) and the malicious code that executes when the compiler
compiles itself.</li>
</ol>

<p>Note that for procedure (2) to work properly, the malicious program that the
compiler executes when asked to compile itself must be able to print its own
source code, so that it can insert its source code into the modified code to be
compiled. Programs that can do so are called
<a href="https://en.wikipedia.org/wiki/Quine_(computing)">quines</a>.</p>

<p>Our resulting compiler looks like</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>compile (code)
{
  /* If the code we're compiling is code for the Unix login command */
  if (match (code, login_code_pattern))
  {
    compile (backdoor);
    return;
  }

  /* If the code we're compiling is similar to the compiler source code */
  if (match (code, compiler_code_pattern))
  {
    compile (compiler_code_with_both_if_statements_inserted);
    return;
  }

  else
  {
    /* Do regular compilation things */
    ...
  }
}
</code></pre></div></div>

<p>Now, when we compile the C compiler with itself, we obtain a binary that
includes the code to insert a backdoor upon compilation of the Unix kernel login
command. We finally delete our modifications to the compiler code, so that we
leave no trace of our exploit; however, the exploit code remains within the 
binary of the C compiler.</p>

<p>Since the C compiler compiles itself, any future (perfectly exploit-free)
version of the C compiler that is compiled by our poisoned binary will include
the backdoor due to procedure (2). And, if the Unix kernel is compiled by
our poisoned binary, it will include the login backdoor, as desired.</p>

<h3 id="the-moral-of-the-story">The Moral of the Story</h3>

<p>Thompson’s solution is initially quite worrying: if you can’t trust the C
compiler, and you can’t trust the compiler binary, what do you do? You can
re-build the compiler binary, but you can’t trust the binary you used to
re-build… and so on, in an indefinite loop of recursive paranoia.</p>

<p>The moral of the paper, then, is quite simple: it’s impossible to operate
without trusting someone. Unless you’ve written all (and I mean ALL) the code
yourself, you’ll have to trust the security of some part of the program-handling
process. Indeed, as Thompson states,</p>

<blockquote>
  <p>In demonstrating the possibility of this attack, I picked on the C compiler. I
could have picked on any program-handling program such as an assembler, a
loader, or even hardware microcode. As the level of program gets lower, these
bugs will be harder and harder to detect. A well-installed microcode bug will
be almost impossible to detect.</p>
</blockquote>

<h3 id="notes">Notes</h3>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Technically, both of these steps require solving the Halting problem — to determine whether two sources do the same thing, you’d have to prove that they both halt in the same circumstances — but a semantically similar match for login/compiler source code is likely enough in practice. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

    </div>
    <div id='bibliography'>
        <div class='wrap'>
            <ol class="bibliography"><li><span id="thompson1984reflections">Thompson, K. (1984). Reflections on trusting trust. <i>Communications of the ACM</i>, <i>27</i>(8), 761–763.</span></li></ol>
        </div>
    </div>
</div>
</body>
</html>